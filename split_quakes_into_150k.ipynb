{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import TRAIN_INFO, AC_DATA, MU, STD, CV_SIZE\n",
    "from utils import T, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_csv(TRAIN_INFO)\n",
    "ac_data = np.load(AC_DATA)['acoustic_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ac_data = scale(ac_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ac_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = np.load(AC_DATA)['acoustic_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quake_period(i):\n",
    "        index_start, chunk_length = train_info['index_start'][i], train_info['chunk_length'][i]\n",
    "        t_start, t_end = train_info['t_start'][i], train_info['t_end'][i]\n",
    "        ac_data_period = ac_data[ index_start : index_start + chunk_length ]\n",
    "        ttf_data_period = np.linspace(t_start, t_end, chunk_length, dtype=np.float32)\n",
    "        return ac_data_period, ttf_data_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = []\n",
    "ttfs = []\n",
    "y_periods = []\n",
    "for index, period in train_info.iterrows():\n",
    "    ix_start = int(period['index_start'])\n",
    "    chunk_length = int(period['chunk_length'])\n",
    "    t_start = period['t_start']\n",
    "    t_end = period['t_end']\n",
    "    y_period = index\n",
    "    period_data = ac_data[ix_start: ix_start+chunk_length]\n",
    "    period_ttf = np.linspace(t_start, t_end, chunk_length, dtype=np.float32)\n",
    "    split_length = 150000\n",
    "    period_splits = []\n",
    "    period_ys = []\n",
    "    for i in range(chunk_length//split_length):\n",
    "        x = period_data[i*split_length:(i+1)*split_length]\n",
    "        y = period_ttf[i*split_length:(i+1)*split_length][-1]\n",
    "        period_splits.append(x)\n",
    "        period_ys.append(y)\n",
    "    print('    ',len(period_splits), np.mean(period_ys))\n",
    "    seqs.extend(period_splits)\n",
    "    ttfs.extend(period_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_seqs = [scale(x) for x in tqdm(seqs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_seqs = []\n",
    "# for x in tqdm(seqs):\n",
    "#     max_val = max(x)\n",
    "#     min_val = min(x)\n",
    "#     scaled = (x-min_val)/(max_val-min_val)\n",
    "#     scaled_seqs.append(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqs = scaled_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(seqs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rescale y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [np.log(1+x) for x in ttfs] # to undo : [np.exp(x)+1 for x in ys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttfs = ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = np.arange(0, max(ttfs), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification=np.digitize(ttfs, buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = classification - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = {}\n",
    "n = (classification==1).mean()\n",
    "for w in np.unique(classification):\n",
    "    wgts[w] = n/(classification == w).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(wgts, 'class_weights.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=np.unique(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in classification:\n",
    "    print(wgts[x])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1_wgts = [wgts[i] for i in classification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_pickle(l1_wgts, 'l1_wgts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs = []\n",
    "# ys = []\n",
    "# s = 250\n",
    "# for i in list(classes):\n",
    "#     s = int(0.5*s)\n",
    "#     print(s)\n",
    "#     ixs=np.where(classification==int(i))[0]\n",
    "#     ixs = random.sample(list(ixs), s)\n",
    "#     ixs = list(ixs)\n",
    "#     x = [seqs[a] for a in ixs]\n",
    "#     y = [ttfs[a] for a in ixs]\n",
    "#     xs.extend(x)\n",
    "#     ys.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqs = xs\n",
    "# ttfs = ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ttfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seqs), len(scaled_seqs), len(ttfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idxs():\n",
    "    idxs = list(np.arange(len(seqs)))\n",
    "    samples = int(len(idxs)*CV_SIZE)\n",
    "    cv_idxs = random.sample(idxs, samples)\n",
    "    train_idxs = [x for x in idxs if x not in cv_idxs]\n",
    "    return train_idxs, cv_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idxs, cv_idxs = get_idxs()\n",
    "# train_set = [(T(scale(seqs[a])), T(scale(ttfs[a])) for a in train_idxs]\n",
    "# cv_set = [(T(seqs[a]), T(ttfs[a])) for a in cv_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idxs, cv_idxs = get_idxs()\n",
    "# train_set = [(T(seqs[a]), T(ttfs[a])) for a in train_idxs]\n",
    "# cv_set = [(T(seqs[a]), T(ttfs[a])) for a in cv_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, cv_idxs = get_idxs()\n",
    "train_set = [(T(scaled_seqs[a]), T(classification[a].astype(np.int64))) for a in train_idxs]\n",
    "cv_set = [(T(scaled_seqs[a]), T(classification[a].astype(np.int64))) for a in cv_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idxs, cv_idxs = get_idxs()\n",
    "# train_set = [(T(seqs[a].astype(np.float32)), T(scaled_seqs[a]), T(ttfs[a])) for a in train_idxs]\n",
    "# cv_set = [(T(seqs[a].astype(np.float32)), T(scaled_seqs[a]), T(ttfs[a])) for a in cv_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = [classification[a] for a in train_idxs]\n",
    "l1_wgts = [wgts[i] for i in train_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(l1_wgts, 'l1_wgts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(train_set, 'train_set.pkl')\n",
    "pd.to_pickle(cv_set, 'cv_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = pd.read_pickle('train_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = torch.stack([x[1] for x in q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
